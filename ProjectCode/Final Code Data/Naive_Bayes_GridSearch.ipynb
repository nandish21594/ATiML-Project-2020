{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes_GridSearch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_CuBCglIO45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e08e2853-8258-4a19-fbd8-20c0203fb072"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjTD5mnGLKt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import tokenize\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from lexical_diversity import lex_div as ld\n",
        "from nltk.util import ngrams\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import os\n",
        "import codecs\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "from collections import OrderedDict\n",
        "# import nlp\n",
        "import spacy\n",
        "from textstat.textstat import textstatistics, legacy_round\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#Using Min Max scaler for NAive bayes so as to bound the values between 0 and 1\n",
        "#Negative values won't work for probability computations\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#GridSearch for hyperparams tuning and classification_report for generating report after param tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import en_core_web_sm\n",
        "from sklearn import svm\n",
        "#Naive Bayes from SKLearn\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nlp = en_core_web_sm.load()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlmRRdiw6mtp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "90e4637a-b5ca-4b75-d12e-6af8dbfd958c"
      },
      "source": [
        "data = pd.read_csv('final_features_without_null_values.csv',encoding=\"ISO-8859-1\")\n",
        "\n",
        "# Split Train and Test Data\n",
        "X  = data.iloc[:,:-1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, data['class'].values, stratify = data['class'].values, test_size = 0.2)\n",
        "df_y_train = pd.DataFrame(y_train, columns=['class'])\n",
        "df_y_test = pd.DataFrame(y_test, columns=['class'])\n",
        "print(\"Number of samples in training data :\", X_train.shape[0])\n",
        "print(\"Number of samples in test data :\", X_test.shape[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples in training data : 795\n",
            "Number of samples in test data : 199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um3z4iYc8G9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "6b7c2e86-8562-4cc7-cceb-130910e4353b"
      },
      "source": [
        "#Check the distribution of data for different classes\n",
        "train_class_distribution = df_y_train['class'].value_counts().sort_index()\n",
        "test_class_distribution = df_y_test['class'].value_counts().sort_index()\n",
        "\n",
        "print(\"\\ntraining distribution:\\n\\n\", train_class_distribution)\n",
        "print(\"\\ntest distribution: \\n\\n\", test_class_distribution)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training distribution:\n",
            "\n",
            " 0      2\n",
            "1      4\n",
            "2     89\n",
            "3      5\n",
            "4      5\n",
            "5    633\n",
            "6     14\n",
            "7     29\n",
            "8     14\n",
            "Name: class, dtype: int64\n",
            "\n",
            "test distribution: \n",
            "\n",
            " 1      1\n",
            "2     22\n",
            "3      1\n",
            "4      1\n",
            "5    159\n",
            "6      4\n",
            "7      7\n",
            "8      4\n",
            "Name: class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lbZBm4a8fgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scaling the features using min max normalization as naive bayes cannot handle negative values\n",
        "scaler = MinMaxScaler()\n",
        "train_df = scaler.fit_transform(X_train)\n",
        "test_df = scaler.fit_transform(X_test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRZvNsF_9aMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "34a56084-4257-4894-e6da-09e57b740c56"
      },
      "source": [
        "# Alpha=Smoothening parameter(0 for no smoothening)\n",
        "clf = MultinomialNB(alpha=.45)\n",
        "clf.fit(train_df, y_train)\n",
        "pred = clf.predict(test_df)\n",
        "\n",
        "\n",
        "print('****************Evaluation Metrics (average = macro) for test data original***************')\n",
        "print('F1 Score: ',metrics.f1_score(y_test, pred, average='macro'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test, pred, average='macro'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test, pred, average='macro'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test, pred))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************Evaluation Metrics (average = macro) for test data original***************\n",
            "F1 Score:  0.11103351955307263\n",
            "Precision Score:  0.09987437185929648\n",
            "Recall Score:  0.125\n",
            "Accuracy:  0.7989949748743719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD3ryNHR6fNd",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50QPgolS-Oqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "73a976ec-0e54-49cf-d6e6-1f894d6bdebb"
      },
      "source": [
        "#Tune hyper parameter using gridsearch cv to set the best hyper parameter\n",
        "# Set the parameters by cross-validation\n",
        "tuned_parameters = [{'alpha': [0.45,0.25,0.40,0.55]}]\n",
        "scores = [ 'recall','f1']\n",
        "\n",
        "for score in scores:\n",
        "\tprint(\"# Tuning hyper-parameters for %s\" % score)\n",
        "\tclf = GridSearchCV(MultinomialNB(), tuned_parameters, scoring='%s_macro' % score)\n",
        "\tclf.fit(train_df, y_train)\n",
        "\n",
        "\tprint(\"Best parameters set found on development set:\")\n",
        "\tprint(clf.best_params_)\n",
        "\tprint(\"Grid scores on development set:\")\n",
        "\tmeans = clf.cv_results_['mean_test_score']\n",
        "\tstds = clf.cv_results_['std_test_score']\n",
        "\tfor mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "\t\tprint(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
        "\tprint(\"Detailed classification report:\")\n",
        "\tprint(\"The model is trained on the full development set.\")\n",
        "\tprint(\"The scores are computed on the full evaluation set.\")\n",
        "\ty_true, y_pred = y_test, clf.predict(test_df)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for recall\n",
            "Best parameters set found on development set:\n",
            "{'alpha': 0.45}\n",
            "Grid scores on development set:\n",
            "0.122 (+/-0.011) for {'alpha': 0.45}\n",
            "0.122 (+/-0.011) for {'alpha': 0.25}\n",
            "0.122 (+/-0.011) for {'alpha': 0.4}\n",
            "0.122 (+/-0.011) for {'alpha': 0.55}\n",
            "Detailed classification report:\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "# Tuning hyper-parameters for f1\n",
            "Best parameters set found on development set:\n",
            "{'alpha': 0.45}\n",
            "Grid scores on development set:\n",
            "0.108 (+/-0.010) for {'alpha': 0.45}\n",
            "0.108 (+/-0.010) for {'alpha': 0.25}\n",
            "0.108 (+/-0.010) for {'alpha': 0.4}\n",
            "0.108 (+/-0.010) for {'alpha': 0.55}\n",
            "Detailed classification report:\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMbnbyhiAFyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "d9854544-1103-4274-a76c-22ba02f10884"
      },
      "source": [
        "# Alpha=Smoothening parameter(0 for no smoothening)\n",
        "# Other hyperparams for naive bayes fit_prior & class prior\n",
        "# As we don't know prior probability of classes we are going with uniform prior for classes\n",
        "\n",
        "print('****************Evaluation Metrics (average = macro) for test data original***************')\n",
        "print('F1 Score: ',metrics.f1_score(y_test, pred, average='macro'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test, pred, average='macro'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test, pred, average='macro'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test, pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************Evaluation Metrics (average = macro) for test data original***************\n",
            "F1 Score:  0.11103351955307263\n",
            "Precision Score:  0.09987437185929648\n",
            "Recall Score:  0.125\n",
            "Accuracy:  0.7989949748743719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le0i4CLixWPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "947df07b-ec69-47b4-c4ca-6959828b72fa"
      },
      "source": [
        "print('*******************Evaluation Metrics (average = weighted) for test data original*****************************')\n",
        "print('F1 Score: ',metrics.f1_score(y_test, pred, average='weighted'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test, pred, average='weighted'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test, pred, average='weighted'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test, pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*******************Evaluation Metrics (average = weighted) for test data original*****************************\n",
            "F1 Score:  0.7097217933241626\n",
            "Precision Score:  0.6383929698744981\n",
            "Recall Score:  0.7989949748743719\n",
            "Accuracy:  0.7989949748743719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}
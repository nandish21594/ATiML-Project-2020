{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_AND_RandomForest_on_Original_Features.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1YLWE1MtOSN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "62954349-a9e4-4164-9326-812012062e28"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VD2sn0NtdMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import tokenize\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk.util import ngrams\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import os\n",
        "import codecs\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "from collections import OrderedDict\n",
        "# import nlp\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import sklearn.utils as utils\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "nlp = en_core_web_sm.load()\n",
        "nlp.max_length = 3050000\n",
        "#Supress warning in console\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2W2YjJIt_KQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Importing original features extracted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37EETsCjthY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "7c414312-60d4-4210-d871-c5adfdde20a5"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/ATML Project/Gutenberg_English_Fiction_1k/final_features_without_null_values.csv\", encoding=\"ISO-8859-1\", delimiter=\",\")\n",
        "data"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>postive</th>\n",
              "      <th>neutral</th>\n",
              "      <th>negative</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>TTR</th>\n",
              "      <th>person_count</th>\n",
              "      <th>she_pronoun</th>\n",
              "      <th>he_pronoun</th>\n",
              "      <th>ease_of_readability</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.121</td>\n",
              "      <td>0.777</td>\n",
              "      <td>0.102</td>\n",
              "      <td>5048</td>\n",
              "      <td>0.858659</td>\n",
              "      <td>104</td>\n",
              "      <td>68</td>\n",
              "      <td>309</td>\n",
              "      <td>83.40</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.154</td>\n",
              "      <td>0.765</td>\n",
              "      <td>0.081</td>\n",
              "      <td>911</td>\n",
              "      <td>0.866100</td>\n",
              "      <td>17</td>\n",
              "      <td>54</td>\n",
              "      <td>127</td>\n",
              "      <td>78.15</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.170</td>\n",
              "      <td>0.738</td>\n",
              "      <td>0.092</td>\n",
              "      <td>8891</td>\n",
              "      <td>0.864052</td>\n",
              "      <td>201</td>\n",
              "      <td>313</td>\n",
              "      <td>392</td>\n",
              "      <td>90.04</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.113</td>\n",
              "      <td>0.803</td>\n",
              "      <td>0.085</td>\n",
              "      <td>8798</td>\n",
              "      <td>0.876325</td>\n",
              "      <td>280</td>\n",
              "      <td>162</td>\n",
              "      <td>408</td>\n",
              "      <td>94.47</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.172</td>\n",
              "      <td>0.703</td>\n",
              "      <td>0.125</td>\n",
              "      <td>1065</td>\n",
              "      <td>0.864347</td>\n",
              "      <td>19</td>\n",
              "      <td>75</td>\n",
              "      <td>98</td>\n",
              "      <td>79.83</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>0.152</td>\n",
              "      <td>0.763</td>\n",
              "      <td>0.085</td>\n",
              "      <td>19591</td>\n",
              "      <td>0.865487</td>\n",
              "      <td>480</td>\n",
              "      <td>456</td>\n",
              "      <td>572</td>\n",
              "      <td>79.90</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>990</th>\n",
              "      <td>0.133</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.087</td>\n",
              "      <td>6036</td>\n",
              "      <td>0.877662</td>\n",
              "      <td>235</td>\n",
              "      <td>197</td>\n",
              "      <td>322</td>\n",
              "      <td>80.37</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>0.112</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.088</td>\n",
              "      <td>5498</td>\n",
              "      <td>0.860010</td>\n",
              "      <td>193</td>\n",
              "      <td>86</td>\n",
              "      <td>365</td>\n",
              "      <td>78.89</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>0.134</td>\n",
              "      <td>0.752</td>\n",
              "      <td>0.114</td>\n",
              "      <td>5370</td>\n",
              "      <td>0.873383</td>\n",
              "      <td>124</td>\n",
              "      <td>145</td>\n",
              "      <td>219</td>\n",
              "      <td>84.28</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>0.106</td>\n",
              "      <td>0.803</td>\n",
              "      <td>0.091</td>\n",
              "      <td>964</td>\n",
              "      <td>0.858335</td>\n",
              "      <td>49</td>\n",
              "      <td>38</td>\n",
              "      <td>73</td>\n",
              "      <td>75.43</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>994 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     postive  neutral  negative  ...  he_pronoun  ease_of_readability  class\n",
              "0      0.121    0.777     0.102  ...         309                83.40      2\n",
              "1      0.154    0.765     0.081  ...         127                78.15      5\n",
              "2      0.170    0.738     0.092  ...         392                90.04      5\n",
              "3      0.113    0.803     0.085  ...         408                94.47      8\n",
              "4      0.172    0.703     0.125  ...          98                79.83      5\n",
              "..       ...      ...       ...  ...         ...                  ...    ...\n",
              "989    0.152    0.763     0.085  ...         572                79.90      5\n",
              "990    0.133    0.780     0.087  ...         322                80.37      5\n",
              "991    0.112    0.800     0.088  ...         365                78.89      2\n",
              "992    0.134    0.752     0.114  ...         219                84.28      2\n",
              "993    0.106    0.803     0.091  ...          73                75.43      5\n",
              "\n",
              "[994 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2rlt7tfuLzT",
        "colab_type": "text"
      },
      "source": [
        "##Splitting Training and Test data using Stratified Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlTyDcrgtrgG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e063f148-be7a-4090-c9c5-bba1c325b533"
      },
      "source": [
        "x_true = data.drop(['class'], axis=1)\n",
        "y_true = data[['class']]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_true, y_true, stratify = y_true, test_size = 0.2)\n",
        "print(\"Number of samples in training data :\", x_train.shape[0])\n",
        "print(\"Number of samples in test data :\", x_test.shape[0])\n",
        "\n",
        "# Checking total no. of data points for each class in train and test data\n",
        "\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "unique1, counts1 = np.unique(y_test, return_counts=True)\n",
        "print(dict(zip(unique1, counts1)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples in training data : 795\n",
            "Number of samples in test data : 199\n",
            "{0: 2, 1: 4, 2: 89, 3: 5, 4: 5, 5: 633, 6: 14, 7: 29, 8: 14}\n",
            "{1: 1, 2: 22, 3: 1, 4: 1, 5: 159, 6: 4, 7: 7, 8: 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRzKK3kPug4E",
        "colab_type": "text"
      },
      "source": [
        "##Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctGPZtxzt3r5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7e8723c9-79e0-4f3c-8840-6ab19110a5c0"
      },
      "source": [
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "#scaler = MinMaxScaler()\n",
        "#x_train = scaler.fit_transform(x_train)\n",
        "#x_test = scaler.fit_transform(x_test)\n",
        "#print(x_test)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)\n",
        "print(x_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.06511518  1.74150534 -1.59721349 ... -0.44734719 -0.47480792\n",
            "   1.48175408]\n",
            " [-0.26367818  0.11976323 -0.65537783 ... -0.55766397 -0.78661394\n",
            "   2.02704466]\n",
            " [-1.60188852  1.30228352 -1.3074179  ...  2.95241523  1.24721165\n",
            "   2.20076555]\n",
            " ...\n",
            " [-0.93278335 -0.08295454  0.64870232 ... -1.52042854 -1.54486947\n",
            "   2.58801837]\n",
            " [ 2.87596916 -2.17770477 -0.14823555 ...  1.07703006 -0.38976992\n",
            "   1.80748076]\n",
            " [ 1.38334994 -0.45460377 -1.74211128 ...  1.47818197  1.24012515\n",
            "   1.63496626]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm5jf6F8zqjA",
        "colab_type": "text"
      },
      "source": [
        "#RandomForestClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5twGFzEYzsj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# train model\n",
        "y = utils.validation.column_or_1d(y_train, warn=False)\n",
        "rfc = RandomForestClassifier(n_estimators=10).fit(x_train, y)\n",
        "# predict on test set\n",
        "rfc_pred = rfc.predict(x_test)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRwQYbB3z2lU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a3991993-f493-46fa-cddf-dccc84ec1281"
      },
      "source": [
        "print('\\n *******************Evaluation Metrics (average = weighted) for test data original***************************** \\n ')\n",
        "\n",
        "print('F1 Score: ', metrics.f1_score(y_test, rfc_pred, average='weighted'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test, rfc_pred, average='weighted'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test, rfc_pred, average='weighted'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test, rfc_pred))\n",
        "\n",
        "print('\\n *******************Evaluation Metrics (average = macro) for test data original***************************** \\n ')\n",
        "\n",
        "print('F1 Score: ', metrics.f1_score(y_test, rfc_pred, average='macro'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test, rfc_pred, average='macro'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test, rfc_pred, average='macro'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test, rfc_pred))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " *******************Evaluation Metrics (average = weighted) for test data original***************************** \n",
            " \n",
            "F1 Score:  0.7399209260031397\n",
            "Precision Score:  0.720079063210466\n",
            "Recall Score:  0.7788944723618091\n",
            "Accuracy:  0.7788944723618091\n",
            "\n",
            " *******************Evaluation Metrics (average = macro) for test data original***************************** \n",
            " \n",
            "F1 Score:  0.16527945489046056\n",
            "Precision Score:  0.19039671577655\n",
            "Recall Score:  0.15850894388630238\n",
            "Accuracy:  0.7788944723618091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnnI6iBlpXaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "7f9e35db-4420-4d16-cd5a-69ae5f6ba9fc"
      },
      "source": [
        "tuned_parameters = [{'n_estimators': [5,10,15,20,25]}] # random forest parameter\n",
        "scores = ['precision', 'recall','f1']\n",
        "y = utils.validation.column_or_1d(y_train, warn=False)\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, scoring='%s_macro' % score)\n",
        "    clf.fit(x_train, y)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print(clf.best_params_)\n",
        "    print(\"Grid scores on development set:\")\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
        "    print(\"Detailed classification report:\")\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    y_true, y_pred = y_test, clf.predict(x_test)\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "Best parameters set found on development set:\n",
            "{'n_estimators': 10}\n",
            "Grid scores on development set:\n",
            "0.148 (+/-0.032) for {'n_estimators': 5}\n",
            "0.182 (+/-0.155) for {'n_estimators': 10}\n",
            "0.170 (+/-0.068) for {'n_estimators': 15}\n",
            "0.179 (+/-0.148) for {'n_estimators': 20}\n",
            "0.162 (+/-0.059) for {'n_estimators': 25}\n",
            "Detailed classification report:\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "# Tuning hyper-parameters for recall\n",
            "Best parameters set found on development set:\n",
            "{'n_estimators': 5}\n",
            "Grid scores on development set:\n",
            "0.160 (+/-0.033) for {'n_estimators': 5}\n",
            "0.153 (+/-0.037) for {'n_estimators': 10}\n",
            "0.143 (+/-0.033) for {'n_estimators': 15}\n",
            "0.138 (+/-0.039) for {'n_estimators': 20}\n",
            "0.144 (+/-0.032) for {'n_estimators': 25}\n",
            "Detailed classification report:\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "# Tuning hyper-parameters for f1\n",
            "Best parameters set found on development set:\n",
            "{'n_estimators': 5}\n",
            "Grid scores on development set:\n",
            "0.160 (+/-0.051) for {'n_estimators': 5}\n",
            "0.145 (+/-0.035) for {'n_estimators': 10}\n",
            "0.147 (+/-0.033) for {'n_estimators': 15}\n",
            "0.134 (+/-0.044) for {'n_estimators': 20}\n",
            "0.151 (+/-0.012) for {'n_estimators': 25}\n",
            "Detailed classification report:\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.20      0.41      0.27        22\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.83      0.72      0.77       159\n",
            "           6       0.17      0.25      0.20         4\n",
            "           7       0.00      0.00      0.00         7\n",
            "           8       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.62       199\n",
            "   macro avg       0.15      0.17      0.16       199\n",
            "weighted avg       0.69      0.62      0.65       199\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwcQPyn1z1VC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dealing with Imbalanced Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggv9r2fXamXK",
        "colab_type": "text"
      },
      "source": [
        "# Necessary Files installation and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7FxP1-r-oFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIJLtdDXo-V5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "513c9a61-f91c-4fd4-860f-d3272deb29d7"
      },
      "source": [
        "!pip install lexical_diversity"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lexical_diversity in /usr/local/lib/python3.6/dist-packages (0.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI7Q7U6C-wYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "76dbc67a-ad83-4095-9200-da126aca634b"
      },
      "source": [
        "!pip install textstat"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.6/dist-packages (from textstat) (0.9.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQzcKovVKoS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "52b145cb-5e40-403e-99e5-0e4513869d59"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIPsDHkR_J6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import tokenize\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from lexical_diversity import lex_div as ld\n",
        "from nltk.util import ngrams\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import os\n",
        "import codecs\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "from collections import OrderedDict\n",
        "# import nlp\n",
        "import spacy\n",
        "from textstat.textstat import textstatistics, legacy_round\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import en_core_web_sm\n",
        "from sklearn import svm\n",
        "nlp = en_core_web_sm.load()\n",
        "nlp.max_length = 3050000\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score,precision_score,recall_score\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdW1kyPQ0-u-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "b83b6f2d-aece-431b-b5d8-6641a4aff4f9"
      },
      "source": [
        "!pip uninstall sklearn -y\n",
        "!pip install Cython\n",
        "!pip install git+https://github.com/scikit-learn/scikit-learn.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling sklearn-0.0:\n",
            "  Successfully uninstalled sklearn-0.0\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.20)\n",
            "Collecting git+https://github.com/scikit-learn/scikit-learn.git\n",
            "  Cloning https://github.com/scikit-learn/scikit-learn.git to /tmp/pip-req-build-k385wye_\n",
            "  Running command git clone -q https://github.com/scikit-learn/scikit-learn.git /tmp/pip-req-build-k385wye_\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.24.dev0) (0.15.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.24.dev0) (1.4.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.24.dev0) (1.18.5)\n",
            "Building wheels for collected packages: scikit-learn\n",
            "  Building wheel for scikit-learn (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-learn: filename=scikit_learn-0.24.dev0-cp36-cp36m-linux_x86_64.whl size=17535204 sha256=81647c13b900d05cbf4686a3d84422a8f8a5a915316c1aa21fbd408a0f089d9f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3d2w8bhl/wheels/7a/25/c4/63026649a3d39acb6ae783b2c72fcbe96f4ed2aa61c33edc1b\n",
            "Successfully built scikit-learn\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.dev0 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrEAh23Fzg3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "03280768-df5b-4ca7-f3bb-e3907eb07272"
      },
      "source": [
        "!pip install -U imbalanced-learn"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imbalanced-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/81/8db4d87b03b998fda7c6f835d807c9ae4e3b141f978597b8d7f31600be15/imbalanced_learn-0.7.0-py3-none-any.whl (167kB)\n",
            "\r\u001b[K     |██                              | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.23 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.24.dev0)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl9aUJY05MaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4255de57-7994-4291-a697-8d6636c64511"
      },
      "source": [
        "#  In order to make use of imblearn library sklearn's version 0.23 or higher is required.\n",
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEcu11Mazkgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45c8d4c4-9b03-4902-da42-319a65dbe339"
      },
      "source": [
        "# check version number\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from collections import Counter\n",
        "print(imblearn.__version__)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2MRgxk6aZYm",
        "colab_type": "text"
      },
      "source": [
        "# Importing original features extracted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNys30BgSOAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e2bb8838-2893-41f5-9199-879523659a06"
      },
      "source": [
        "original_df1 = pd.read_csv(\"final_features_without_null_values.csv\",encoding=\"ISO-8859-1\")\n",
        "original_df1['class'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    792\n",
              "2    111\n",
              "7     36\n",
              "8     18\n",
              "6     18\n",
              "4      6\n",
              "3      6\n",
              "1      5\n",
              "0      2\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAmZPHTuVLR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_df2 = original_df1.drop('class',axis=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPwxBva7SaIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b525307f-6a66-49b4-8d30-f27007ba19ad"
      },
      "source": [
        "# Split Train and Test Data\n",
        "y_true_original = original_df1['class'].values\n",
        "X_train_original, X_test_original, y_train_original, y_test_original = train_test_split(original_df2, y_true_original, stratify = y_true_original, test_size = 0.2)\n",
        "\n",
        "print(\"Number of samples in training data :\", X_train_original.shape[0])\n",
        "print(\"Number of samples in test data :\", X_test_original.shape[0])\n",
        "\n",
        "#  Scaling data using Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "X_train_original = scaler.fit_transform(X_train_original)\n",
        "X_test_original = scaler.fit_transform(X_test_original)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples in training data : 795\n",
            "Number of samples in test data : 199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SydMHgYhn1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c17410e3-035a-4530-dcab-e357413f2df7"
      },
      "source": [
        "# Checking total no. of data points for each class in train and test data\n",
        "\n",
        "unique, counts = np.unique(y_train_original, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "unique1, counts1 = np.unique(y_test_original, return_counts=True)\n",
        "print(dict(zip(unique1, counts1)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 2, 1: 4, 2: 89, 3: 5, 4: 5, 5: 633, 6: 14, 7: 29, 8: 14}\n",
            "{1: 1, 2: 22, 3: 1, 4: 1, 5: 159, 6: 4, 7: 7, 8: 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j4X4fAMaMRO",
        "colab_type": "text"
      },
      "source": [
        "# UpSampling Dataset to remove Imbalance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57MXg8hWAikc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "3bc89102-1d37-478b-a000-d35f07e9029d"
      },
      "source": [
        "#  This is method one in which  we have upsampled the whole data and then split data into train and test data.\n",
        "\n",
        "imbalanced_df = pd.read_csv(\"final_features_without_null_values.csv\",encoding=\"ISO-8859-1\")\n",
        "imbalanced_df2 = imbalanced_df.drop('class',axis=1)\n",
        "y_true_imbalanced = imbalanced_df['class'].values\n",
        "\n",
        "# We have made use of SMOTE technique of upsampling for generating synthetic data\n",
        "\n",
        "oversample = SMOTE(k_neighbors=1)\n",
        "X_balanced,y_true_balanced = oversample.fit_resample(imbalanced_df2,y_true_imbalanced)\n",
        "# print(Counter(y_true_imbalanced))\n",
        "\n",
        "#  We are creating new data frame with balanced data.\n",
        "balanced_df = X_balanced.copy()\n",
        "balanced_df['class'] = y_true_balanced\n",
        "\n",
        "# checking for class which had only 2 data points previous and now has all data points , size matches the majority class.\n",
        "print(imbalanced_df[imbalanced_df['class'] == 0])\n",
        "print(balanced_df[balanced_df['class'] == 0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     postive  neutral  negative  ...  he_pronoun  ease_of_readability  class\n",
            "102    0.185    0.727     0.088  ...         113                83.21      0\n",
            "454    0.146    0.689     0.165  ...         347                80.91      0\n",
            "\n",
            "[2 rows x 10 columns]\n",
            "       postive   neutral  negative  ...  he_pronoun  ease_of_readability  class\n",
            "102   0.185000  0.727000  0.088000  ...         113            83.210000      0\n",
            "454   0.146000  0.689000  0.165000  ...         347            80.910000      0\n",
            "994   0.150362  0.693250  0.156388  ...         320            81.167255      0\n",
            "995   0.174084  0.716363  0.109553  ...         178            82.566210      0\n",
            "996   0.146729  0.689710  0.163561  ...         342            80.952972      0\n",
            "...        ...       ...       ...  ...         ...                  ...    ...\n",
            "1779  0.171734  0.714074  0.114192  ...         192            82.427646      0\n",
            "1780  0.153176  0.695992  0.150832  ...         303            81.333213      0\n",
            "1781  0.161163  0.703775  0.135062  ...         256            81.804255      0\n",
            "1782  0.175108  0.717362  0.107531  ...         172            82.626618      0\n",
            "1783  0.150884  0.693759  0.155357  ...         317            81.198023      0\n",
            "\n",
            "[792 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXLYqCSsAy8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "balanced_df2 = balanced_df.drop('class',axis=1)\n",
        "y_true_balanced = balanced_df['class'].values"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrckbJtr86CQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a66b168a-1615-4b1c-a012-5f97c1b8bdbd"
      },
      "source": [
        "#  Splitting data into train and test \n",
        "X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced = train_test_split(balanced_df2, y_true_balanced, stratify = y_true_balanced, test_size = 0.2)\n",
        "\n",
        "print(\"Number of samples in balanced training data :\", X_train_balanced.shape[0])\n",
        "print(\"Number of samples in balanced test data :\", X_test_balanced.shape[0])\n",
        "\n",
        "# Scaling data using Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
        "X_test_balanced = scaler.fit_transform(X_test_balanced)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples in balanced training data : 5702\n",
            "Number of samples in balanced test data : 1426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj1dM4G8jgo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "55e0a58a-0bce-48db-c474-1af0b4a0bf04"
      },
      "source": [
        "# Take whole data upsampled , split data into train and test, but take train from upsampled and test from original.\n",
        "\n",
        "#  Trying SVM classifier \n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train_balanced, y_train_balanced)\n",
        "pred_original = clf.predict(X_test_original)\n",
        "\n",
        "print('\\n *******************Evaluation Metrics (average = weighted) for test data original***************************** \\n ')\n",
        "\n",
        "print('F1 Score: ', metrics.f1_score(y_test_original, pred_original, average='weighted'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test_original, pred_original, average='weighted'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test_original, pred_original, average='weighted'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test_original, pred_original))\n",
        "\n",
        "print('\\n *******************Evaluation Metrics (average = macro) for test data original***************************** \\n ')\n",
        "\n",
        "print('F1 Score: ', metrics.f1_score(y_test_original, pred_original, average='macro'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test_original, pred_original, average='macro'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test_original, pred_original, average='macro'))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " *******************Evaluation Metrics (average = weighted) for test data original***************************** \n",
            " \n",
            "F1 Score:  0.615359344421321\n",
            "Precision Score:  0.8115797042041356\n",
            "Recall Score:  0.5628140703517588\n",
            "Accuracy:  0.5628140703517588\n",
            "\n",
            " *******************Evaluation Metrics (average = macro) for test data original***************************** \n",
            " \n",
            "F1 Score:  0.42495089786756457\n",
            "Precision Score:  0.35342570656257827\n",
            "Recall Score:  0.8071602139998366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7kllVPmxqlN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "06d25cfe-a530-4dfd-9866-f335320fd81e"
      },
      "source": [
        "# Trying XGBoost Classifier \n",
        "\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train_balanced, y_train_balanced)\n",
        "y_pred = xgb.predict(X_test_original)\n",
        "\n",
        "print('\\n *******************Evaluation Metrics (average = weighted) for test data original***************************** \\n ')\n",
        "\n",
        "print('F1 Score: ', metrics.f1_score(y_test_original, y_pred, average='weighted'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test_original, y_pred, average='weighted'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test_original, y_pred, average='weighted'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test_original, y_pred))\n",
        "\n",
        "print('\\n *******************Evaluation Metrics (average = macro) for test data original***************************** \\n ')\n",
        "\n",
        "print('F1 Score: ', metrics.f1_score(y_test_original, y_pred, average='macro'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test_original, y_pred, average='macro'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test_original, y_pred, average='macro'))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " *******************Evaluation Metrics (average = weighted) for test data original***************************** \n",
            " \n",
            "F1 Score:  0.6181002611227414\n",
            "Precision Score:  0.7930323291399246\n",
            "Recall Score:  0.5628140703517588\n",
            "Accuracy:  0.5628140703517588\n",
            "\n",
            " *******************Evaluation Metrics (average = macro) for test data original***************************** \n",
            " \n",
            "F1 Score:  0.28526197049516583\n",
            "Precision Score:  0.2525143976969896\n",
            "Recall Score:  0.4468449091090601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1225: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeG5kvfuZ4Mq",
        "colab_type": "text"
      },
      "source": [
        "# DownSampling Technique "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6VRh5jbwzWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df1['class'].value_counts().plot(kind='bar', title='Count (class)')\n",
        "\n",
        "original_df3 = original_df1.drop('class',axis=1)\n",
        "y_true_down = original_df1['class'].values\n",
        "\n",
        "#  Using Tomek Links to do under/down sampling, This technique first calculates Tomek's links and then remove them \n",
        "#  on the basis of distance and check if two samples are nearest to each other.\n",
        "\n",
        "tkl = TomekLinks(sampling_strategy='majority')\n",
        "X_tkl, y_tkl = tkl.fit_sample(original_df3, y_true_down)\n",
        "\n",
        "# print(Counter(y_tkl))\n",
        "\n",
        "#  Splitting data into train and test \n",
        "X_train_down , X_test_down , y_train_down , y_test_down  = train_test_split(X_tkl, y_tkl, stratify = y_tkl, test_size = 0.2)\n",
        "\n",
        "#  Scaling data using Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "X_train_down  = scaler.fit_transform(X_train_down)\n",
        "X_test_down  = scaler.fit_transform(X_test_down)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QjLQEWhdOdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "121e4135-3a97-4883-de24-a4a995477ad9"
      },
      "source": [
        "#  Trying SVM classifier \n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train_down, y_train_down)\n",
        "pred_down = clf.predict(X_test_down)\n",
        "\n",
        "print('\\n *******************Evaluation Metrics (average = weighted) for test data***************************** \\n ')\n",
        "\n",
        "print('F1 Score: ', metrics.f1_score(y_test_down, pred_down, average='weighted'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test_down, pred_down, average='weighted'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test_down, pred_down, average='weighted'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test_down, pred_down))\n",
        "\n",
        "print('\\n *******************Evaluation Metrics (average = macro) for test data***************************** \\n ')\n",
        "\n",
        "print('F1 Score: ', metrics.f1_score(y_test_down, pred_down, average='macro'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test_down, pred_down, average='macro'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test_down, pred_down, average='macro'))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " *******************Evaluation Metrics (average = weighted) for test data***************************** \n",
            " \n",
            "F1 Score:  0.6887796887796888\n",
            "Precision Score:  0.6143170197224251\n",
            "Recall Score:  0.7837837837837838\n",
            "Accuracy:  0.7837837837837838\n",
            "\n",
            " *******************Evaluation Metrics (average = macro) for test data***************************** \n",
            " \n",
            "F1 Score:  0.10984848484848485\n",
            "Precision Score:  0.09797297297297297\n",
            "Recall Score:  0.125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1225: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5VUF244dKrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "38c2657d-36ea-4c60-fef0-439c76718ae4"
      },
      "source": [
        "#  Trying XGBoost Classifier \n",
        "\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train_down , y_train_down)\n",
        "y_pred_down  = xgb.predict(X_test_down)\n",
        "\n",
        "print('\\n *******************Evaluation Metrics (average = weighted) for test data ***************************** \\n ')\n",
        "\n",
        "\n",
        "print('F1 Score: ', metrics.f1_score(y_test_down, y_pred_down, average='weighted'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test_down, y_pred_down, average='weighted'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test_down, y_pred_down, average='weighted'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test_down, y_pred_down))\n",
        "\n",
        "print('\\n *******************Evaluation Metrics (average = macro) for test data ***************************** \\n ')\n",
        "\n",
        "print('F1 Score: ', metrics.f1_score(y_test_down, y_pred_down, average='macro'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test_down, y_pred_down, average='macro'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test_down, y_pred_down, average='macro'))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " *******************Evaluation Metrics (average = weighted) for test data ***************************** \n",
            " \n",
            "F1 Score:  0.7289107289107287\n",
            "Precision Score:  0.6891891891891891\n",
            "Recall Score:  0.7891891891891892\n",
            "Accuracy:  0.7891891891891892\n",
            "\n",
            " *******************Evaluation Metrics (average = macro) for test data ***************************** \n",
            " \n",
            "F1 Score:  0.148380355276907\n",
            "Precision Score:  0.15811128526645768\n",
            "Recall Score:  0.14996081504702194\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1225: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}